{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTANT CODE SNIPPETS\n",
    "One stop destination for all code snippets,\n",
    "which are useful for processes in ML.\n",
    "\n",
    "The code gets updated from time to time as\n",
    "I learn more and more techniques and \n",
    "document them.\n",
    "\n",
    "Happy Machine Learning.\n",
    "We are the future.\n",
    "\n",
    "@author: Bikram Dutta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Frequecy in text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adrian', 'baby', 'rambo', 'rocky']\n",
      "[[0 1 0 2]\n",
      " [0 0 2 2]\n",
      " [2 0 1 1]]\n",
      "{'adrian': 2, 'baby': 1, 'rambo': 3, 'rocky': 5}\n",
      "{'baby': 1, 'rocky': 2}\n",
      "{'rambo': 2, 'rocky': 2}\n",
      "{'adrian': 2, 'rambo': 1, 'rocky': 1}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "sampleTextList = [['rocky','baby','rocky'], ['rocky','rocky', 'rambo', 'rambo'], ['adrian', 'rocky', 'adrian', 'rambo']]\n",
    "\n",
    "\n",
    "cv = CountVectorizer()\n",
    "newList = []\n",
    "for sampleList in sampleTextList:\n",
    "    newList.append(' '.join(sampleList))\n",
    "    \n",
    "sampleTextList = newList\n",
    "\n",
    "# for just count matrix\n",
    "cv_fit = cv.fit_transform(sampleTextList)\n",
    "\n",
    "print(cv.get_feature_names())\n",
    "print(cv_fit.toarray())\n",
    "\n",
    "wordList = cv.get_feature_names()\n",
    "countList = cv_fit.toarray().sum(axis=0)\n",
    "wordCountMap = dict(zip(wordList,countList))\n",
    "\n",
    "print(wordCountMap)\n",
    "\n",
    "# for every text in the list\n",
    "\n",
    "for text in sampleTextList:\n",
    "    cv = CountVectorizer()\n",
    "    cv_fit = cv.fit_transform(text.split())\n",
    "    wordList = cv.get_feature_names()\n",
    "    countList = cv_fit.toarray().sum(axis=0)\n",
    "    wordCountMap = dict(zip(wordList,countList))\n",
    "    print(wordCountMap)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Numpy Array :  ['rocky' 'baby' 'rocky' 'rocky' 'rocky' 'rambo' 'rambo' 'adrian' 'rocky'\n",
      " 'adrian' 'rambo']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'adrian': 2, 'baby': 1, 'rambo': 3, 'rocky': 5}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "arr = numpy.array(newList)\n",
    "print('Original Numpy Array : ' , arr)\n",
    " \n",
    "# Get a tuple of unique values & their frequency in numpy array\n",
    "uniqueValues, occurCount = numpy.unique(arr, return_counts=True)\n",
    "\n",
    "valueDict = dict(zip(uniqueValues, occurCount))\n",
    " \n",
    "# print(\"Unique Values : \" , uniqueValues)\n",
    "# print(\"Occurrence Count : \", occurCount)\n",
    "valueDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rocky',\n",
       " 'baby',\n",
       " 'rocky',\n",
       " 'rocky',\n",
       " 'rocky',\n",
       " 'rambo',\n",
       " 'rambo',\n",
       " 'adrian',\n",
       " 'rocky',\n",
       " 'adrian',\n",
       " 'rambo']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampleList = [['rocky','baby','rocky'], ['rocky','rocky', 'rambo', 'rambo'], ['adrian', 'rocky', 'adrian', 'rambo']]\n",
    "newList = []\n",
    "for sample in sampleList:\n",
    "    newList.extend(sample)\n",
    "    \n",
    "newList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print'. Did you mean print(\"The list printed sorting by age in descending order: \")? (<ipython-input-68-020e051b33ac>, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-68-020e051b33ac>\"\u001b[1;36m, line \u001b[1;32m9\u001b[0m\n\u001b[1;33m    print \"The list printed sorting by age in descending order: \"\u001b[0m\n\u001b[1;37m                                                                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m Missing parentheses in call to 'print'. Did you mean print(\"The list printed sorting by age in descending order: \")?\n"
     ]
    }
   ],
   "source": [
    "wordCountDf = pd.DataFrame(list(zip(wordList,countList)),columns =['Word', 'Count']) \n",
    "wordCountDf.sort_values(by=['Count'], inplace=True, ascending = False)\n",
    "wordCountDf.reset_index(inplace=True, drop=True)\n",
    "wordCountDf\n",
    "# list(wordCountDf['Word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rocky baby rocky', 'rocky rocky rambo rambo', 'adrian rocky adrian rambo']\n"
     ]
    }
   ],
   "source": [
    "sampleTextList = [['rocky baby rocky', 'rocky rocky rambo rambo'], ['adrian rocky adrian rambo']]\n",
    "wordList = []\n",
    "list(map(wordList.extend, sampleTextList))\n",
    "print(wordList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.63245553 0.36514837]\n",
      " [0.63245553 1.         0.57735027]\n",
      " [0.36514837 0.57735027 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "sampleTextList = ['rocky baby rocky', 'rocky rocky rambo rambo', 'adrian rocky adrian rambo']\n",
    "cv = CountVectorizer()\n",
    "\n",
    "# for just count matrix\n",
    "cv_fit = cv.fit_transform(sampleTextList)\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "similarity_scores = cosine_similarity(cv_fit)\n",
    "\n",
    "print(similarity_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# n-gram Containment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'this': 5, 'is': 2, 'an': 0, 'answer': 1, 'text': 4, 'source': 3}\n",
      "{'this is': 5, 'is an': 2, 'an answer': 0, 'answer text': 1, 'is source': 3, 'source text': 4}\n",
      "  (0, 5)\t1\n",
      "  (0, 2)\t1\n",
      "  (0, 0)\t1\n",
      "  (0, 1)\t1\n",
      "  (0, 4)\t1\n",
      "  (1, 5)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 4)\t1\n",
      "  (1, 3)\t1\n",
      "[[1 1 1 0 1 1]\n",
      " [0 0 1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "a_text = \"This is an answer text\"\n",
    "s_text = \"This is a source text\"\n",
    "\n",
    "# set n\n",
    "n = 1\n",
    "\n",
    "# instantiate an ngram counter\n",
    "    counts = CountVectorizer(analyzer='word', ngram_range=(n,n))\n",
    "\n",
    "# create a dictionary of n-grams by calling `.fit`\n",
    "vocab2int = counts.fit([a_text, s_text]).vocabulary_\n",
    "\n",
    "# print dictionary of words:index\n",
    "print(vocab2int)\n",
    "\n",
    "# create a vocabulary for 2-grams\n",
    "# counts_2grams = None\n",
    "    counts_2grams = CountVectorizer(analyzer='word', ngram_range=(n+1,n+1))\n",
    "# create a dictionary of 2-grams by calling `.fit`\n",
    "vocabFor2grams = counts_2grams.fit([a_text, s_text]).vocabulary_\n",
    "print(vocabFor2grams)\n",
    "\n",
    "\n",
    "# create array of n-gram counts for the answer and source text\n",
    "ngrams = counts.fit_transform([a_text, s_text])\n",
    "print(ngrams)\n",
    "# row = the 2 texts and column = indexed vocab terms (as mapped above)\n",
    "# ex. column 0 = 'an', col 1 = 'answer'.. col 4 = 'text'\n",
    "ngram_array = ngrams.toarray()\n",
    "print(ngram_array)\n",
    "\n",
    "def containment(ngram_array):\n",
    "    ''' Containment is a measure of text similarity. It is the normalized, \n",
    "       intersection of ngram word counts in two texts.\n",
    "       :param ngram_array: an array of ngram counts for an answer and source text.\n",
    "       :return: a normalized containment value.'''\n",
    "    temp = list(ngram_array)\n",
    "    count = len(temp[0])\n",
    "    commonTerms = 0\n",
    "    commonIndexes = []\n",
    "    while count>0:\n",
    "        index = len(temp[0]) - count\n",
    "        if temp[0][index] == temp[1][index]:\n",
    "            commonTerms +=1\n",
    "            commonIndexes.append(index)\n",
    "        count = count -1 \n",
    "    \n",
    "    containment = commonTerms / np.count_nonzero(temp[0] > 0)\n",
    "    \n",
    "    # your code here\n",
    "    \n",
    "    return containment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'containment' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-78c5079c4852>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# test out your code\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcontainment_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontainment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mngrams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Containment: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontainment_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'containment' is not defined"
     ]
    }
   ],
   "source": [
    "# test out your code\n",
    "containment_val = containment(ngrams.toarray())\n",
    "\n",
    "print('Containment: ', containment_val)\n",
    "\n",
    "# note that for the given texts, and n = 1\n",
    "# the containment value should be 3/5 or 0.6\n",
    "assert containment_val==0.6, 'Unexpected containment value for n=1.'\n",
    "print('Test passed!')\n",
    "\n",
    "\n",
    "# test for n = 2\n",
    "counts_2grams = CountVectorizer(analyzer='word', ngram_range=(2,2))\n",
    "bigram_counts = counts_2grams.fit_transform([a_text, s_text])\n",
    "\n",
    "# calculate containment\n",
    "containment_val = containment(bigram_counts.toarray())\n",
    "\n",
    "print('Containment for n=2 : ', containment_val)\n",
    "\n",
    "# the containment value should be 1/4 or 0.25\n",
    "assert containment_val==0.25, 'Unexpected containment value for n=2.'\n",
    "print('Test passed!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1\n",
    "answer_filename = 'g0pA_taska.txt'\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "counts = CountVectorizer(analyzer='word', ngram_range=(n,n))\n",
    "vocab = counts.fit(list(complete_df.Text)).vocabulary_\n",
    "# print(vocab)\n",
    "ngrams = counts.fit_transform(list(complete_df.Text))\n",
    "# print(ngrams)\n",
    "ngram_array = ngrams.toarray()\n",
    "\n",
    "\n",
    "complete_df['ngrams'] = list(ngram_array)\n",
    "\n",
    "def getSourceNgram(complete_df,answer_filename):\n",
    "    task = list(complete_df[complete_df.File == answer_filename]['Task'])[0]\n",
    "    print(task)\n",
    "    source_ngram = list(complete_df[(complete_df['Task'] == task) & (complete_df.Class == -1)].ngrams)[0].tolist()\n",
    "#     print('Source ngram: ', source_ngram)\n",
    "    return source_ngram\n",
    "\n",
    "def getNgramsForText(complete_df,answer_filename):\n",
    "    return list(complete_df[complete_df.File == answer_filename].ngrams)[0].tolist()\n",
    "\n",
    "resultant = []\n",
    "for element in ngram_array:\n",
    "    if resultant == []:\n",
    "        resultant = element\n",
    "    \n",
    "    else:\n",
    "        resultant = np.bitwise_and(resultant,element)\n",
    "\n",
    "globalCommonTerms = np.count_nonzero(resultant>0)\n",
    "\n",
    "ngramsForAnswer = getNgramsForText(complete_df,answer_filename)\n",
    "ngramsForSource = getSourceNgram(complete_df,answer_filename)\n",
    "commonbetweenSrcAndAns = np.bitwise_and(np.array(ngramsForAnswer),np.array(ngramsForSource))\n",
    "\n",
    "containment = np.count_nonzero(commonbetweenSrcAndAns > 0) / np.count_nonzero(np.array(ngramsForAnswer) > 0)\n",
    "\n",
    "print(len(commonbetweenSrcAndAns),len(ngramsForSource), len(resultant))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_array = [[1,1,1,0,1],\n",
    "              [1,0,1,1,1],\n",
    "              [1,1,0,0,1],\n",
    "              [1,1,1,1,1]]\n",
    "\n",
    "temp = list(ngram_array)\n",
    "count = len(temp[0])\n",
    "commonTerms = 0\n",
    "commonIndexes = []\n",
    "while count>0:\n",
    "    index = len(temp[0]) - count\n",
    "    if temp[0][index] == temp[1][index]:\n",
    "        commonTerms +=1\n",
    "        commonIndexes.append(index)\n",
    "    count = count -1 \n",
    "\n",
    "containment = commonTerms / np.count_nonzero(temp[0] > 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\InstalledPrograms\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "ngram_array = [[1,1,1,0,1],\n",
    "              [1,0,1,1,1],\n",
    "              [1,1,0,0,1],\n",
    "              [1,1,1,1,1]]\n",
    "\n",
    "resultant = []\n",
    "for element in ngram_array:\n",
    "    if resultant == []:\n",
    "        resultant = element\n",
    "    \n",
    "    else:\n",
    "        resultant = np.bitwise_and(resultant,element)\n",
    "        \n",
    "np.count_nonzero(resultant>0)\n",
    "\n",
    "# np.bitwise_and(ngram_array[0:2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
